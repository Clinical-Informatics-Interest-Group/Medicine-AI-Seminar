{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Clinical-Informatics-Interest-Group/Medicine-AI-Seminar/blob/main/session_2/IntroML.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extremely Short intro to Python\n",
    "### (and Jupyter Notebooks)\n",
    "\n",
    "Python is one of the most popular Machine Learning languages in academia and industry.  \n",
    "It's also thankfully easier to read than many other programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, medical students!\n"
     ]
    }
   ],
   "source": [
    "# Place your cursor in this cell and press 'shift' + 'enter'\n",
    "print(\"Hello, medical students!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Hello, medical students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing happened there ^ because the line started with '#'.\n",
    "# Coders call this \"commenting out\" code. In python, any line that starts with '#' is\n",
    "# not evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python does math well, too.\n",
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n",
       "\n",
       "Prints the values to a stream, or to sys.stdout by default.\n",
       "Optional keyword arguments:\n",
       "file:  a file-like object (stream); defaults to the current sys.stdout.\n",
       "sep:   string inserted between values, default a space.\n",
       "end:   string appended after the last value, default a newline.\n",
       "flush: whether to forcibly flush the stream.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you want more information about a function from Jupyter, simply place a '?' in front\n",
    "# of it and evaulate it with 'shift+enter'.\n",
    "?print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Breast Cancer Wisconsin Dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))\n",
    "\"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\"  \n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First let's train our own neurons\n",
    "![img](./images/histology.webp)\n",
    "Rakha, Emad & Reis-Filho, Jorge & Baehner, Frederick & Dabbs, David & Decker, Thomas & Eusebi, Vincenzo & Fox, Stephen & Ichihara, Shu & Jacquemier, Jocelyne & Lakhani, Sr & Palacios, Jos√© & Richardson, Andrea & Schnitt, Stuart & Schmitt, Fernando & Tan, Puay-Hoon & Tse, Gary & Badve, Sunil & Ellis, Ian. (2010). Breast cancer prognostic classification in the molecular era: the role of histological grade. Breast cancer research : BCR. 12. 207. 10.1186/bcr2607. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These import statements bring new functions for us to use.\n",
    "# This saves us from having to write them ourselves.\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Let's use a function from 'datasets' to load the breast cancer data\n",
    "# and assign it to 'tumor'\n",
    "tumor = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to \"Hold Out\" half the data for validation\n",
    "# we need to write some code that allows us to separate\n",
    "# it at the halfway point.\n",
    "\n",
    "# Find the length of the data set\n",
    "length = len(tumor.data)\n",
    "# Halfway point\n",
    "midpoint = (length // 2)\n",
    "# New start point\n",
    "secondhalf = midpoint + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data features (independant variables) to a matrix 'X'\n",
    "# which the Perceptron will make predictions on. 'y' is the ground\n",
    "# truth the Perceptron will compare it's predictions to.\n",
    "X = pd.DataFrame(tumor.data[:midpoint, :])\n",
    "y = tumor.target[:midpoint]\n",
    "# We'll hold some data from model testing in order to test its \"real world\" performance\n",
    "X_validate = pd.DataFrame(tumor.data[secondhalf:, :])\n",
    "y_validate = tumor.target[secondhalf:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Here, we tell 'train_test_split' to take 30% of our training\n",
    "# data set and assign it to X_test. X_train is the data the perceptron\n",
    "# will learn from by predicting malignant or not. X_test is the data\n",
    "# internally validates the trained algorithm.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>13.85</td>\n",
       "      <td>15.18</td>\n",
       "      <td>88.99</td>\n",
       "      <td>587.4</td>\n",
       "      <td>0.09516</td>\n",
       "      <td>0.07688</td>\n",
       "      <td>0.04479</td>\n",
       "      <td>0.03711</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.05853</td>\n",
       "      <td>...</td>\n",
       "      <td>14.98</td>\n",
       "      <td>21.74</td>\n",
       "      <td>98.37</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.09993</td>\n",
       "      <td>0.2955</td>\n",
       "      <td>0.06912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>19.16</td>\n",
       "      <td>26.60</td>\n",
       "      <td>126.20</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>0.14530</td>\n",
       "      <td>0.19210</td>\n",
       "      <td>0.09664</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.06220</td>\n",
       "      <td>...</td>\n",
       "      <td>23.72</td>\n",
       "      <td>35.90</td>\n",
       "      <td>159.80</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.3841</td>\n",
       "      <td>0.57540</td>\n",
       "      <td>0.18720</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.09720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>11.74</td>\n",
       "      <td>14.02</td>\n",
       "      <td>74.24</td>\n",
       "      <td>427.3</td>\n",
       "      <td>0.07813</td>\n",
       "      <td>0.04340</td>\n",
       "      <td>0.02245</td>\n",
       "      <td>0.02763</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.06113</td>\n",
       "      <td>...</td>\n",
       "      <td>13.31</td>\n",
       "      <td>18.26</td>\n",
       "      <td>84.70</td>\n",
       "      <td>533.7</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.06735</td>\n",
       "      <td>0.08290</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.06688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>19.40</td>\n",
       "      <td>18.18</td>\n",
       "      <td>127.20</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.16260</td>\n",
       "      <td>0.09464</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>0.05892</td>\n",
       "      <td>...</td>\n",
       "      <td>23.79</td>\n",
       "      <td>28.65</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.3749</td>\n",
       "      <td>0.43160</td>\n",
       "      <td>0.22520</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.07787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>16.24</td>\n",
       "      <td>18.77</td>\n",
       "      <td>108.80</td>\n",
       "      <td>805.1</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.18020</td>\n",
       "      <td>0.19480</td>\n",
       "      <td>0.09052</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>0.06684</td>\n",
       "      <td>...</td>\n",
       "      <td>18.55</td>\n",
       "      <td>25.09</td>\n",
       "      <td>126.90</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.50260</td>\n",
       "      <td>0.17320</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>0.10630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1       2       3        4        5        6        7       8   \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "279  13.85  15.18   88.99   587.4  0.09516  0.07688  0.04479  0.03711  0.2110   \n",
       "280  19.16  26.60  126.20  1138.0  0.10200  0.14530  0.19210  0.09664  0.1902   \n",
       "281  11.74  14.02   74.24   427.3  0.07813  0.04340  0.02245  0.02763  0.2101   \n",
       "282  19.40  18.18  127.20  1145.0  0.10370  0.14420  0.16260  0.09464  0.1893   \n",
       "283  16.24  18.77  108.80   805.1  0.10660  0.18020  0.19480  0.09052  0.1876   \n",
       "\n",
       "          9   ...     20     21      22      23      24      25       26  \\\n",
       "0    0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.71190   \n",
       "1    0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.24160   \n",
       "2    0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.45040   \n",
       "3    0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.68690   \n",
       "4    0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.40000   \n",
       "..       ...  ...    ...    ...     ...     ...     ...     ...      ...   \n",
       "279  0.05853  ...  14.98  21.74   98.37   670.0  0.1185  0.1724  0.14560   \n",
       "280  0.06220  ...  23.72  35.90  159.80  1724.0  0.1782  0.3841  0.57540   \n",
       "281  0.06113  ...  13.31  18.26   84.70   533.7  0.1036  0.0850  0.06735   \n",
       "282  0.05892  ...  23.79  28.65  152.40  1628.0  0.1518  0.3749  0.43160   \n",
       "283  0.06684  ...  18.55  25.09  126.90  1031.0  0.1365  0.4706  0.50260   \n",
       "\n",
       "          27      28       29  \n",
       "0    0.26540  0.4601  0.11890  \n",
       "1    0.18600  0.2750  0.08902  \n",
       "2    0.24300  0.3613  0.08758  \n",
       "3    0.25750  0.6638  0.17300  \n",
       "4    0.16250  0.2364  0.07678  \n",
       "..       ...     ...      ...  \n",
       "279  0.09993  0.2955  0.06912  \n",
       "280  0.18720  0.3258  0.09720  \n",
       "281  0.08290  0.3101  0.06688  \n",
       "282  0.22520  0.3590  0.07787  \n",
       "283  0.17320  0.2770  0.10630  \n",
       "\n",
       "[284 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate 'X' to see the data in a nice table\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.548789</td>\n",
       "      <td>19.429648</td>\n",
       "      <td>95.006761</td>\n",
       "      <td>694.523239</td>\n",
       "      <td>0.098614</td>\n",
       "      <td>0.112790</td>\n",
       "      <td>0.102681</td>\n",
       "      <td>0.055858</td>\n",
       "      <td>0.185730</td>\n",
       "      <td>0.063019</td>\n",
       "      <td>...</td>\n",
       "      <td>17.017299</td>\n",
       "      <td>26.129120</td>\n",
       "      <td>112.371937</td>\n",
       "      <td>960.666901</td>\n",
       "      <td>0.136632</td>\n",
       "      <td>0.281742</td>\n",
       "      <td>0.309525</td>\n",
       "      <td>0.127427</td>\n",
       "      <td>0.302461</td>\n",
       "      <td>0.086318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.607309</td>\n",
       "      <td>4.321089</td>\n",
       "      <td>24.868854</td>\n",
       "      <td>360.689460</td>\n",
       "      <td>0.013757</td>\n",
       "      <td>0.056942</td>\n",
       "      <td>0.083489</td>\n",
       "      <td>0.039458</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>...</td>\n",
       "      <td>4.970160</td>\n",
       "      <td>6.389541</td>\n",
       "      <td>34.543913</td>\n",
       "      <td>581.489238</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.174084</td>\n",
       "      <td>0.218540</td>\n",
       "      <td>0.067030</td>\n",
       "      <td>0.069890</td>\n",
       "      <td>0.020447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.897500</td>\n",
       "      <td>16.377500</td>\n",
       "      <td>77.152500</td>\n",
       "      <td>437.100000</td>\n",
       "      <td>0.089807</td>\n",
       "      <td>0.070155</td>\n",
       "      <td>0.037097</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.057513</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>21.397500</td>\n",
       "      <td>86.037500</td>\n",
       "      <td>543.775000</td>\n",
       "      <td>0.122125</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.072740</td>\n",
       "      <td>0.261175</td>\n",
       "      <td>0.072950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.760000</td>\n",
       "      <td>19.315000</td>\n",
       "      <td>89.390000</td>\n",
       "      <td>584.550000</td>\n",
       "      <td>0.097765</td>\n",
       "      <td>0.103750</td>\n",
       "      <td>0.085465</td>\n",
       "      <td>0.050035</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.061855</td>\n",
       "      <td>...</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>25.970000</td>\n",
       "      <td>105.700000</td>\n",
       "      <td>765.450000</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.237100</td>\n",
       "      <td>0.274550</td>\n",
       "      <td>0.121950</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.081545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.027500</td>\n",
       "      <td>22.025000</td>\n",
       "      <td>111.150000</td>\n",
       "      <td>904.375000</td>\n",
       "      <td>0.107025</td>\n",
       "      <td>0.144475</td>\n",
       "      <td>0.148175</td>\n",
       "      <td>0.083645</td>\n",
       "      <td>0.199350</td>\n",
       "      <td>0.066697</td>\n",
       "      <td>...</td>\n",
       "      <td>20.130000</td>\n",
       "      <td>30.307500</td>\n",
       "      <td>133.050000</td>\n",
       "      <td>1260.250000</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.384975</td>\n",
       "      <td>0.426725</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.330925</td>\n",
       "      <td>0.095692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2499.000000</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>33.120000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>220.800000</td>\n",
       "      <td>3432.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2            3           4   \\\n",
       "count  284.000000  284.000000  284.000000   284.000000  284.000000   \n",
       "mean    14.548789   19.429648   95.006761   694.523239    0.098614   \n",
       "std      3.607309    4.321089   24.868854   360.689460    0.013757   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.062510   \n",
       "25%     11.897500   16.377500   77.152500   437.100000    0.089807   \n",
       "50%     13.760000   19.315000   89.390000   584.550000    0.097765   \n",
       "75%     17.027500   22.025000  111.150000   904.375000    0.107025   \n",
       "max     28.110000   39.280000  188.500000  2499.000000    0.144700   \n",
       "\n",
       "               5           6           7           8           9   ...  \\\n",
       "count  284.000000  284.000000  284.000000  284.000000  284.000000  ...   \n",
       "mean     0.112790    0.102681    0.055858    0.185730    0.063019  ...   \n",
       "std      0.056942    0.083489    0.039458    0.029041    0.007552  ...   \n",
       "min      0.019380    0.000000    0.000000    0.116700    0.049960  ...   \n",
       "25%      0.070155    0.037097    0.024362    0.166700    0.057513  ...   \n",
       "50%      0.103750    0.085465    0.050035    0.184200    0.061855  ...   \n",
       "75%      0.144475    0.148175    0.083645    0.199350    0.066697  ...   \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440  ...   \n",
       "\n",
       "               20          21          22           23          24  \\\n",
       "count  284.000000  284.000000  284.000000   284.000000  284.000000   \n",
       "mean    17.017299   26.129120  112.371937   960.666901    0.136632   \n",
       "std      4.970160    6.389541   34.543913   581.489238    0.023286   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.300000   21.397500   86.037500   543.775000    0.122125   \n",
       "50%     15.870000   25.970000  105.700000   765.450000    0.136500   \n",
       "75%     20.130000   30.307500  133.050000  1260.250000    0.150400   \n",
       "max     33.120000   49.540000  220.800000  3432.000000    0.222600   \n",
       "\n",
       "               25          26          27          28          29  \n",
       "count  284.000000  284.000000  284.000000  284.000000  284.000000  \n",
       "mean     0.281742    0.309525    0.127427    0.302461    0.086318  \n",
       "std      0.174084    0.218540    0.067030    0.069890    0.020447  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.154075    0.139300    0.072740    0.261175    0.072950  \n",
       "50%      0.237100    0.274550    0.121950    0.290500    0.081545  \n",
       "75%      0.384975    0.426725    0.177900    0.330925    0.095692  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the 'describe' method on X returns some useful information\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important to standardize the numerical values in every feature, so that no feature is disproportionally weighted.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We should fit the 'Standard Scaler' to the data we're going to train the Perceptron on.\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "# And then standardize the data by transforming it with the fit 'Standard Scaler'\n",
    "X_train_std = sc.transform(X_train)\n",
    "# Now apply the same standardizing to the test and validation sets\n",
    "X_test_std = sc.transform(X_test)\n",
    "X_valid_std = sc.transform(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(eta0=0.1, random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Let's call the Perceptron we're about to train 'neuron', and give it\n",
    "# two initial instructions (in the form of parameters). 'eta0' is the \"learning\n",
    "# rate\", which tell's the Perceptron how much it should change its predictions\n",
    "# each time it gets them wrong. 'random_state=1' tells the Perceptron to randomly\n",
    "# weight each feature of the data from the start.\n",
    "neuron = Perceptron(eta0=0.1, random_state=1)\n",
    "\n",
    "# Next we'll tell neuron to learn from the data features 'X_train_std' by attempting to predict\n",
    "# the outcome 'y_train'\n",
    "neuron.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534883720930233"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the accuracy by scoring 'neuron' against the test data\n",
    "neuron.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/envs/dsmed/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9418604651162791"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what happens if we only allow the Perceptron to learn\n",
    "# from a single prediction.\n",
    "weak_neuron = Perceptron(max_iter=1, eta0=0.1, random_state=1)\n",
    "weak_neuron.fit(X_train_std, y_train)\n",
    "weak_neuron.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954225352112676"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lastly, we validate the neuron with the validation\n",
    "# data held out from training.\n",
    "neuron.score(X_valid_std, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Diagnosis by Fine Needle Aspirate\n",
    "- Sensitivity: 74 percent (95% CI 72 to 77 percent)\n",
    "- Specificity: 96 percent (95% CI 94 to 98 percent)\n",
    "\n",
    "Wang M, He X, Chang Y, Sun G, Thabane L. \"A sensitivity and specificity comparison of fine needle aspiration cytology and core needle biopsy in evaluation of suspicious breast lesions: A systematic review and meta-analysis.\" Breast. 2017;31:157. Epub 2016 Nov 17. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 66,   1],\n",
       "       [ 12, 205]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Explore this code to see how we can describe the\n",
    "# sensitivity and specificity of our 'neuron'\n",
    "y_validate_pred = neuron.predict(X_valid_std)\n",
    "confusion_matrix(y_validate, y_validate_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity :  0.9447004608294931\n",
      "Specificity :  0.9850746268656716\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_validate, y_validate_pred).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "print('Sensitivity : ', sensitivity)\n",
    "print('Specificity : ', specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
